# -*- coding: utf-8 -*-
"""deployment code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19JhN3l0829i_r_pti54wUn5AFeEZl6OT
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from torchvision import models
from PIL import Image
import os
import random
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st

st.title("Human Action Recognition using CNN Models - ResNet")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
extract_path = 'C:/Users/karth/OneDrive/Desktop/JPEGImages'
class_paths = {
    'Applauding': os.path.join(extract_path, 'Applauding'),
    'Blowing_Bubbles': os.path.join(extract_path, 'Blowing_Bubbles'),
    'Brushing_Teeth': os.path.join(extract_path, 'Brushing_Teeth'),
    'Cleaning_The_Floor': os.path.join(extract_path, 'Cleaning_The_Floor'),
    'Climbing': os.path.join(extract_path, 'Climbing'),
    'Cooking': os.path.join(extract_path, 'Cooking'),
    'Cutting_Trees': os.path.join(extract_path, 'Cutting_Trees'),
    'Cutting_Vegetables': os.path.join(extract_path, 'Cutting_Vegetables'),
    'Drinking': os.path.join(extract_path, 'Drinking'),
    'Feeding_a_horse': os.path.join(extract_path, 'Feeding_a_horse'),
    'Fishing': os.path.join(extract_path, 'Fishing'),
    'Fixing_a_bike': os.path.join(extract_path, 'Fixing_a_bike'),
    'Fixing_a_Car': os.path.join(extract_path, 'Fixing_a_Car'),
    'Gardening': os.path.join(extract_path, 'Gardening'),
    'Holding_an_Umbrella': os.path.join(extract_path, 'Holding_an_Umbrella'),
    'Jumping': os.path.join(extract_path, 'Jumping'),
    'Looking_through_a_Microscope': os.path.join(extract_path, 'Looking_through_a_Microscope'),
    'Looking_through_a_Telescope': os.path.join(extract_path, 'Looking_through_a_Telescope'),
    'Phoning': os.path.join(extract_path, 'Phoning'),
    'Playing_Guitar': os.path.join(extract_path, 'Playing_Guitar'),
    'Playing_Violin': os.path.join(extract_path, 'Playing_Violin'),
    'Pouring_Liquid': os.path.join(extract_path, 'Pouring_Liquid'),
    'Pushing_a_Cart': os.path.join(extract_path, 'Pushing_a_Cart'),
    'Reading': os.path.join(extract_path, 'Reading'),
    'Riding_a_Bike': os.path.join(extract_path, 'Riding_a_Bike'),
    'Riding_a_Horse': os.path.join(extract_path, 'Riding_a_Horse'),
    'Rowing_a_Boat': os.path.join(extract_path, 'Rowing_a_Boat'),
    'Running': os.path.join(extract_path, 'Running'),
    'Shooting_an_Arrow': os.path.join(extract_path, 'Shooting_an_Arrow'),
    'Smoking': os.path.join(extract_path, 'Smoking'),
    'Taking_Photos': os.path.join(extract_path, 'Taking_Photos'),
    'Texting_Message': os.path.join(extract_path, 'Texting_Message'),
    'Throwing_Frisby': os.path.join(extract_path, 'Throwing_Frisby'),
    'Using_a_Computer': os.path.join(extract_path, 'Using_a_Computer'),
    'Walking_the_dog': os.path.join(extract_path, 'Walking_the_dog'),
    'Washing_Dishes': os.path.join(extract_path, 'Washing_Dishes'),
    'Watching_TV': os.path.join(extract_path, 'Watching_TV'),
    'Waving_Hands': os.path.join(extract_path, 'Waving_Hands'),
    'Writing_on_a_Board': os.path.join(extract_path, 'Writing_on_a_Board'),
    'Writing_on_a_Book': os.path.join(extract_path, 'Writing_on_a_Book')
}

classes = list(class_paths.keys())

filepaths = []
labels = []

for class_name, class_path in class_paths.items():
    filelist = os.listdir(class_path)
    for filename in filelist:
        filepath = os.path.join(class_path, filename)
        filepaths.append(filepath)
        labels.append(class_name)

class CustomImageDataset(Dataset):
    def __init__(self, filepaths, labels, transform=None):
        self.filepaths = filepaths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.filepaths)

    def __getitem__(self, idx):
        img_path = self.filepaths[idx]
        label = self.labels[idx]
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, label

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

dataset = CustomImageDataset(filepaths, labels, transform=transform)

total_samples = len(filepaths)
train_ratio, val_ratio, test_ratio = 0.75, 0.15, 0.10
train_size = int(train_ratio * total_samples)
val_size = int(val_ratio * total_samples)
test_size = total_samples - train_size - val_size

indices = list(range(total_samples))
random.shuffle(indices)
train_indices = indices[:train_size]
val_indices = indices[train_size:train_size + val_size]
test_indices = indices[train_size + val_size:]

train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)
val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)
test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)

train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)
val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)
test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)

model = models.resnet18(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_paths))
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_model(model, train_loader, val_loader, criterion, optimizer, classes, device, num_epochs=8):
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    for epoch in range(num_epochs):

        model.train()
        running_loss = 0.0
        correct_train = 0
        total_train = 0

        for images, labels_tuple in train_loader:
            inputs = images.to(device)
            labels = torch.tensor([classes.index(label) for label in labels_tuple]).to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)

            _, predicted = torch.max(outputs, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()

        epoch_loss = running_loss / len(train_loader.dataset)
        train_acc = correct_train / total_train
        train_losses.append(epoch_loss)
        train_accuracies.append(train_acc)

        model.eval()
        val_loss = 0.0
        correct_val = 0
        total_val = 0

        with torch.no_grad():
            for images, labels_tuple in val_loader:
                inputs = images.to(device)
                labels = torch.tensor([classes.index(label) for label in labels_tuple]).to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)

                _, predicted = torch.max(outputs, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()

        val_loss /= len(val_loader.dataset)
        val_acc = correct_val / total_val
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        st.write(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')

    return model, train_losses, val_losses, train_accuracies, val_accuracies

num_epochs = 8
model, train_losses, val_losses, train_accuracies, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, classes, device, num_epochs)

plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
st.pyplot()

plt.figure(figsize=(10, 5))
plt.plot(train_accuracies, label='Train Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
st.pyplot()

def predict_random_image(model, train_loader, classes, device):
    model.eval()
    idx = torch.randint(0, len(train_loader.dataset), (1,))
    image, label = train_loader.dataset[idx]
    image_pil = transforms.ToPILImage()(image)
    image_tensor = image.unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(image_tensor)
        _, predicted = torch.max(outputs, 1)
        predicted_class = classes[predicted.item()]

    return image_pil, predicted_class


random_image, random_pred_class = predict_random_image(model, train_loader, classes, device)
st.image(random_image, caption=f'Randomly Selected Image - Predicted Class: {random_pred_class}', use_column_width=True)

if st.button("Refresh"):
    st.experimental_rerun()